"""
The file is named with "offline", since it works offline to get the tracking, it is not about whether "the method is
offline" or not. It is still classified as "online tracking", since only previous frames are used to generate the
tracking.

It is called "offline" since it needs the result from multiple trackers in advance. It is okay to use such a method on
MOT17 challenge.
"""

import os
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"

import cv2
import numpy as np
np.set_printoptions(2, suppress=True)
from loguru import logger

from yolox.tracker import matching
from yolox.tracker.kalman_filter import KalmanFilter
from yolox.tracking_utils.timer import Timer
from yolox.utils.visualize import plot_tracking

min_correspondence_thresh = 5  # > 0, integer
max_lost_track_tolerance = 15  # > 0, integer
appearance_model_keeping_rate = 0.1  # [0, 1]
non_detected_speed_penalty = 0.01  # [0, 1]
iou_similarity_thresh_DRC = 0.5  # [0, 1]
appearance_similarity_thresh = 0.7  # [0, 1]
iou_similarity_thresh_GLC = 0.2  # [0, 1]
box_score_thresh = 0.85  # [0, 1]


class outside_track:
    """
    An outside (outside the original tracker) copy. It can predict automatically (with a KF).
    But its updating is controlled by hard-coded rules or reasoners outside.
    """

    def __init__(self, ID, tlwh, score, appearances = None, appearance_score = 0.0):
        # data
        self.ID = ID
        self.kalman_filter = KalmanFilter()
        self.mean, self.cov = self.kalman_filter.initiate(self.tlwh_to_xyah(tlwh))
        self.score = score  # the quality of a box (generated by NN)
        self.appearances = appearances  # appearance model, color-hist is used here, but can be extended
        self.appearance_score = appearance_score
        self.max_life = 10
        self.life = self.max_life  # how many frames can a track stand with no updates

        self.initialized = False
        self.updated = True  # whether it is just updated
        self.updated_appearance = True  # whether the appearance is just updated

        self.to_update = [[tlwh, score, appearances, appearance_score]]

    def retire(self, t = 1):
        self.life -= t

    def predict(self):
        mean_state = self.mean.copy()
        self.mean, self.cov = self.kalman_filter.predict(mean_state, self.cov)

    @property
    def tlwh(self):
        ret = self.mean[:4].copy()
        ret[2] *= ret[3]
        ret[:2] -= ret[2:] / 2
        return ret

    @property
    def tlbr(self):
        ret = self.tlwh.copy()
        ret[2:] += ret[:2]
        return ret

    @staticmethod
    def tlwh_to_xyah(tlwh):
        ret = np.asarray(tlwh).copy()
        ret[:2] += ret[2:] / 2
        ret[2] /= ret[3]
        return ret

    def initialize(self, tlwh, score, appearances = None, appearance_score = 0):
        #  the KF is not updated, but re-initialized
        self.life = self.max_life
        self.initialized = True
        self.updated = True
        self.updated_appearance = True  # whether the appearance is just updated

        self.kalman_filter = KalmanFilter()
        self.mean, self.cov = self.kalman_filter.initiate(self.tlwh_to_xyah(tlwh))
        self.score = score  # the quality of a box (generated by NN)
        self.appearances = appearances  # appearance model, color-hist is used here, but can be extended
        self.appearance_score = appearance_score

        self.to_update = []

    def update(self, tlwh, score, appearances = None, appearance_score = 0):
        """
        appearance and momentum cannot both be None.
        """

        # re-active
        self.life = self.max_life
        self.updated = True

        # update the KF
        mean, cov = self.kalman_filter.update(self.mean, self.cov, self.tlwh_to_xyah(tlwh))

        # update score
        self.score = score

        # update appearance
        if appearances is not None:
            self.updated_appearance = True
            self.appearances = appearances
            self.appearance_score = appearance_score
            # EMA, observation centric, higher weight for the new box
            mean = self.mean * 0.1 + mean * 0.9
        self.mean = mean
        self.cov = cov

        self.to_update = []

    def next_frame(self):
        # finish the final update, from many possible initialization and updates, pick the best
        pass


def tlwh_to_tlbr(tlwh):
    ret = np.array(tlwh.copy())
    ret[2:] += ret[:2]
    return ret


class external_tracker_manager:

    def __init__(self, path, video_length):
        self.frame = 1
        self.index = 0
        self.length = video_length
        with open(path) as file:
            self.data = file.readlines()
        self.correspondence = {}  # format: {tracker ID: [outside_track ID, count]}

    def next_frame(self):
        if self.frame > self.length:
            return None
        ret = []
        for i in range(self.index, len(self.data)):
            if int(self.data[i].split(",")[0]) == self.frame:
                ret.append([float(each) for each in self.data[i].strip("\n").split(",")])
            else:
                self.index = i
                self.frame += 1
                break
        # format: [frame, object ID, top left x, top left y, width, height, score, -, -, -]
        # tlwh in short
        return ret

    def update_correspondence(self, external_tracker_ID, outside_track_ID):
        if external_tracker_ID in self.correspondence:
            if self.correspondence[external_tracker_ID][0] == outside_track_ID:
                self.correspondence[1] += 1
        else:
            self.correspondence.update({external_tracker_ID: [outside_track_ID, 1]})


class video_manager:

    def __init__(self, path, video_length):
        self.frame_id = 1
        self.path = path
        self.length = video_length

    def next_frame(self):
        if self.frame_id > self.length:
            return None
        path = self.path + str(self.frame_id).zfill(6) + ".jpg"
        self.frame_id += 1
        return cv2.imread(path)


def generate_color_hist(img_patch):
    # BRG color hist
    if img_patch.shape[0] * img_patch.shape[1] == 0:
        return None
    img = cv2.resize(img_patch, (64, 64))
    blue_track = cv2.calcHist([img], [0], None, [25], [0, 256])
    blue_track = blue_track / blue_track.sum()
    red_track = cv2.calcHist([img], [1], None, [25], [0, 256])
    red_track = red_track / red_track.sum()
    green_track = cv2.calcHist([img], [2], None, [25], [0, 256])
    green_track = green_track / green_track.sum()

    return [blue_track, red_track, green_track]


def img_patch(tlbr, img):
    return img[
           min(img.shape[0], max(0, int(tlbr[1]))):
           min(img.shape[0], max(0, int(tlbr[3]))),
           min(img.shape[1], max(0, int(tlbr[0]))):
           min(img.shape[1], max(0, int(tlbr[2]))), :]


def cleanness(tlbr_tracking, tlbr_trackings, inter_iou_similarity, I, img):
    area = abs(tlbr_tracking[0] - tlbr_tracking[2]) * abs(tlbr_tracking[1] - tlbr_tracking[3]) + 1

    mask = np.zeros([img.shape[0], img.shape[1]])

    mask[
    min(img.shape[0], max(0, int(tlbr_tracking[1]))): min(img.shape[0], max(0, int(tlbr_tracking[3]))),
    min(img.shape[1], max(0, int(tlbr_tracking[0]))): min(img.shape[1], max(0, int(tlbr_tracking[2])))] \
        = 1

    for j in range(inter_iou_similarity.shape[1]):
        if inter_iou_similarity[I, j] > 0 and j != I:
            mask[
            min(img.shape[0], max(0, int(tlbr_trackings[j][1]))): min(img.shape[0], max(0, int(tlbr_trackings[j][3]))),
            min(img.shape[1], max(0, int(tlbr_trackings[j][0]))): min(img.shape[1], max(0, int(tlbr_trackings[j][2])))] \
                = 0

    return mask.sum() / area


def compare_color_hist(hist1, hist2):
    # multiply the color-hist similarities of three channels
    return cv2.compareHist(hist1[0], hist2[0], 0) * cv2.compareHist(hist1[1], hist2[1], 0) * cv2.compareHist(
        hist1[2], hist2[2], 0)


# read external tracker results and images

video_length = 1050
imgs_path = ""
external_trackers = {}

video_manager = video_manager(imgs_path, video_length)
for each in external_trackers:
    external_trackers[each] = external_tracker_manager(external_trackers[each], video_length)

frame_id = 1
timer = Timer()
outside_track_ID = 1
outside_tracks = {}
results = []
vid_writer = cv2.VideoWriter(
    "x.mp4",
    cv2.VideoWriter_fourcc(*"mp4v"), 30, (int(1920), int(1080))
)

for _ in range(video_length):

    if frame_id == 201:
        print(1)

    # processing each frame

    if frame_id % 20 == 0:
        logger.info("Processing frame {} ({:.2f} fps)".format(frame_id, 1. / max(1e-5, timer.average_time)))

    # get the frame
    img = video_manager.next_frame()

    # pop outdated outside tracks
    tmp = []
    for each in outside_tracks:
        outside_tracks[each].retire()
        if outside_tracks[each].life < -max_lost_track_tolerance:
            tmp.append(each)
    for each in tmp:
        outside_tracks.pop(each)

    for each_external_tracker in external_trackers:
        tracking = external_trackers[each_external_tracker].next_frame()

        tlbr_tracking = np.array([tlwh_to_tlbr(each[2: 6]) for each in tracking])
        tlbr_outside_tracks = np.array([outside_tracks[each].tlbr for each in outside_tracks])

        # iou similarities between external tracker results and outside tracks, the higher the similar
        iou_similarity = 1 - matching.iou_distance(tlbr_tracking,
                                                   tlbr_outside_tracks,
                                                   img.shape)

        # iou similarities between external trackers, used to find these "pure" (without overlapping) boxes
        inter_iou_similarity = 1 - matching.iou_distance(tlbr_tracking,
                                                         tlbr_tracking,
                                                         img.shape)

        cls = [None for _ in range(len(tracking))]
        hists_target = [None for _ in range(len(tracking))]

        # direct consistency, check the stable correspondence relationship
        # for example, in "external tracker 1", it has "self.correspondence", which maps the "external tracker ID"
        # to "outside track ID"
        I1 = []

        for i, each in enumerate(tracking):

            if cls[i] is not None:
                cl = cls[i]
            else:
                cl = cleanness(tlbr_tracking[i], tlbr_tracking, inter_iou_similarity, i, img)
                cls[i] = cl

            if each[1] in external_trackers[each_external_tracker].correspondence \
                    and external_trackers[each_external_tracker].correspondence[each[1]][1] \
                    > min_correspondence_thresh:
                # if the external track ID has a correspondence (to outside track IDs), and the correspondence is
                # robust enough

                ot_id = external_trackers[each_external_tracker].correspondence[each[1]][0]

                if hists_target[i] is not None:
                    hist_target = hists_target[i]
                else:
                    hist_target = generate_color_hist(img_patch(tlbr_tracking[i], img))
                    hists_target[i] = hist_target

                if hist_target is None:
                    continue

                if ot_id in outside_tracks and outside_tracks[ot_id].life >= 0:
                    # when the outside track is still "on tracking"

                    if iou_similarity[i, list(outside_tracks.keys()).index(ot_id)] > iou_similarity_thresh_DRC:
                        # if iou similarity looks good

                        I1.append(i)

                        # no need to update the appearance often
                        # the appearance will be updated when this appearance is "clean" (with no overlapping)
                        outside_tracks[ot_id].to_update.append([each[2: 6],
                                                                each[6],
                                                                hist_target,
                                                                max(0.1, cl)])
                    else:
                        external_trackers[each_external_tracker].correspondence[each[1]][1] \
                            = max(1, external_trackers[each_external_tracker].correspondence[each[1]][1] - 2)
                else:
                    # here, the outside track is still "considered", but not "on tracking", and so IoU is
                    # no longer reliable, and the appearance is clue used

                    if ot_id in outside_tracks and compare_color_hist(hist_target, outside_tracks[ot_id].appearances) \
                            > appearance_similarity_thresh:
                        # the outside track will be refreshed

                        I1.append(i)

                        outside_tracks[ot_id].to_update.append([each[2: 6],
                                                                each[6],
                                                                hist_target,
                                                                max(0.1, cl)])

        # global consistency,
        # if the correspondence is wrong (or not robust enough), to which outside track ID it should refer
        I2 = []
        for i, each in enumerate(tracking):

            if i in I1:
                continue

            if cls[i] is not None:
                cl = cls[i]
            else:
                cl = cleanness(tlbr_tracking[i], tlbr_tracking, inter_iou_similarity, i, img)
                cls[i] = cl

            if hists_target[i] is not None:
                hist_target = hists_target[i]
            else:
                hist_target = generate_color_hist(img_patch(tlbr_tracking[i], img))
                hists_target[i] = hist_target

            for j, each_id in enumerate(outside_tracks):

                if hist_target is None:
                    continue

                if iou_similarity[i, j] > iou_similarity_thresh_GLC \
                        and compare_color_hist(hist_target, outside_tracks[each_id].appearances) \
                        > appearance_similarity_thresh:
                    # at least the iou similarity should be high enough, and they should look similar

                    I2.append(i)

                    outside_tracks[each_id].to_update.append([each[2: 6],
                                                              each[6],
                                                              hist_target,
                                                              max(0.1, cl)])

                    if each[1] in external_trackers[each_external_tracker].correspondence:
                        # there is a correspondence for this "external ID"
                        ot_id = external_trackers[each_external_tracker].correspondence[each[1]][0]
                        if ot_id == each_id:
                            # correct correspondence
                            external_trackers[each_external_tracker].correspondence[each[1]][1] += 1
                        else:
                            # wrong correspondence
                            external_trackers[each_external_tracker].correspondence[each[1]] = [each_id, 1]
                    else:
                        external_trackers[each_external_tracker].correspondence.update({each[1]: [each_id, 1]})

                    break

        # brand-new outside tracks
        for i, each in enumerate(tracking):

            if i in I1 + I2:
                continue

            if each[6] > box_score_thresh:

                if each[1] not in external_trackers[each_external_tracker].correspondence or (
                        each[1] in external_trackers[each_external_tracker].correspondence and
                        external_trackers[each_external_tracker].correspondence[each[1]][0] not in outside_tracks):
                    # there was a correspondence, but it expired, and the wrong outside track is deleted
                    # then a new correspondence will be created

                    if cls[i] is not None:
                        cl = cls[i]
                    else:
                        cl = cleanness(tlbr_tracking[i], tlbr_tracking, inter_iou_similarity, i, img)
                        cls[i] = cl

                    if hists_target[i] is not None:
                        hist_target = hists_target[i]
                    else:
                        hist_target = generate_color_hist(img_patch(tlbr_tracking[i], img))
                        hists_target[i] = hist_target

                    if hist_target is None:
                        continue

                    outside_tracks.update({outside_track_ID:
                                               outside_track(ID=outside_track_ID,
                                                             tlwh=each[2:6],
                                                             score=each[6],
                                                             appearances=hist_target,
                                                             appearance_score=max(0.1, cl))})
                    external_trackers[each_external_tracker].correspondence.update({each[1]: [outside_track_ID, 1]})
                    outside_track_ID += 1

    # pick the best to update/initialize
    for each in outside_tracks:
        if len(outside_tracks[each].to_update) != 0:
            outside_tracks[each].to_update.sort(key=lambda x: x[1] * x[3])
            d = outside_tracks[each].to_update[-1]
            if not outside_tracks[each].initialized:
                outside_tracks[each].initialize(*d)
            else:
                if outside_tracks[each].life >= 0:
                    if d[-1] > outside_tracks[each].appearance_score or d[-1] > 0.7:
                        outside_tracks[each].update(*d)
                    else:
                        outside_tracks[each].update(tlwh=d[0], score=d[1])
                else:
                    outside_tracks[each].initialize(*d)

    # ==================================================================================================================

    # txt writer
    online_tlwhs = []
    online_ids = []
    online_scores = []
    for each in outside_tracks:

        if outside_tracks[each].life >= 0:

            tlwh = outside_tracks[each].tlwh
            tid = each
            # if not outside_tracks[each].touched_appearance:
            #     tid = -tid
            vertical = tlwh[2] / tlwh[3] > 1.6
            if tlwh[2] * tlwh[3] > 10 and not vertical:
                online_tlwhs.append(tlwh)
                online_ids.append(tid)
                online_scores.append(outside_tracks[each].score)
                results.append(
                    f"{frame_id},{tid},{tlwh[0]:.2f},{tlwh[1]:.2f},{tlwh[2]:.2f},{tlwh[3]:.2f},"
                    f"{outside_tracks[each].score:.2f},-1,-1,-1\n"
                )
    timer.toc()
    online_im = plot_tracking(
        img, online_tlwhs, online_ids, frame_id=frame_id + 1, fps=1. / timer.average_time
    )

    for each in outside_tracks:

        if outside_tracks[each].life >= 0:
            # make the speed of the aspect ratio 0 when not updated (trick often used in many MOT codes)
            if not outside_tracks[each].updated:
                outside_tracks[each].mean[7] = 0
            outside_tracks[each].predict()
            outside_tracks[each].updated = False
            outside_tracks[each].updated_appearance = False

    vid_writer.write(online_im)
    frame_id += 1

res_file = "C:\\Users\\TORY\\OneDrive - Temple University\\AGI research\\RMOT Demo\\RMOT-demo\\OpenNARS-for-Applications-master\\misc\\Python\\YOLOX_outputs\\hai\\res.txt"
with open(res_file, "w") as f:
    f.writelines(results)
logger.info(f"save results to {res_file}")
